{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreyans06/ML-/blob/master/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i38m_sUS2LGg",
        "colab_type": "code",
        "outputId": "ab368958-54a2-4c86-e159-5836e1262850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "\n",
        "def train_test_split(data,split):\n",
        "  train_size=int(len(data)*split)\n",
        "  train_set=[]\n",
        "  test_set=list(data)\n",
        "  while(len(train_set)<train_size):\n",
        "    index=random.randrange(len(test_set))\n",
        "    train_set.append(test_set.pop(index))\n",
        "  return np.array(train_set),np.array(test_set)\n",
        "\n",
        "with open('lab3.csv') as f:\n",
        "  examples=[list(line) for line in csv.reader(f)]\n",
        "traindata=examples[1:]\n",
        "data=np.array(traindata)\n",
        "\n",
        "split_ratio=0.7\n",
        "train_data,test_data=train_test_split(data,split_ratio)\n",
        "\n",
        "\n",
        "test_target=test_data[:,-1]\n",
        "train_target=train_data[:,-1]\n",
        "print('Training data')\n",
        "print(train_data)\n",
        "print('Testing data')\n",
        "print(test_data)\n",
        "test_data=test_data[:,:-1]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data\n",
            "[['sunny' 'hot' 'high' 'strong' 'no']\n",
            " ['overcast' 'hot' 'normal' 'weak' 'yes']\n",
            " ['overcast' 'mild' 'high' 'strong' 'yes']\n",
            " ['sunny' 'mild' 'normal' 'strong' 'yes']\n",
            " ['sunny' 'cool' 'normal' 'weak' 'yes']\n",
            " ['overcast' 'hot' 'high' 'weak' 'yes']\n",
            " ['rain' 'mild' 'high' 'weak' 'yes']\n",
            " ['sunny' 'mild' 'high' 'weak' 'no']\n",
            " ['rain' 'mild' 'normal' 'weak' 'yes']]\n",
            "Testing data\n",
            "[['sunny' 'hot' 'high' 'weak' 'no']\n",
            " ['rain' 'cool' 'normal' 'weak' 'yes']\n",
            " ['rain' 'cool' 'normal' 'strong' 'no']\n",
            " ['overcast' 'cool' 'strong' 'weak' 'yes']\n",
            " ['rain' 'mild' 'high' 'strong' 'no']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7UMWwad-RnM",
        "colab_type": "code",
        "outputId": "cbc56e10-cc9a-4847-904d-23d8d668ec45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "positive_count=0\n",
        "total_count=np.shape(train_target)[0]\n",
        "\n",
        "for tar in train_target:\n",
        "  if(tar=='yes'):\n",
        "    positive_count+=1\n",
        "\n",
        "positive_prob=positive_count/total_count\n",
        "\n",
        "negative_prob=(total_count-positive_count)/total_count\n",
        "\n",
        "attribute_dict={}\n",
        "pred_list=[]\n",
        "\n",
        "for ts_row in test_data:\n",
        "  for ts_attrib in ts_row:\n",
        "    tar_dict={'yes':0,'no':0}\n",
        "    for tr_row in train_data:\n",
        "      for tr_attrib in tr_row:\n",
        "        if(tr_attrib==ts_attrib and tr_row[-1]=='yes'):\n",
        "          tar_dict['yes']+=1\n",
        "        if(tr_attrib==ts_attrib and tr_row[-1]=='no'):\n",
        "          tar_dict['no']+=1\n",
        "        attribute_dict[ts_attrib]=tar_dict\n",
        "  prob_dict={}\n",
        "  for each_attrib in attribute_dict:\n",
        "    pos_prob_attrib=attribute_dict[each_attrib]['yes']/positive_count\n",
        "    neg_prob_attrib=attribute_dict[each_attrib]['no']/(total_count-positive_count)\n",
        "    prob_dict[each_attrib]=[pos_prob_attrib,neg_prob_attrib]\n",
        "  \n",
        "  total_pos_prob=positive_prob\n",
        "  total_neg_prob=negative_prob\n",
        "\n",
        "  for each_attrib in ts_row:\n",
        "    total_pos_prob*=prob_dict[each_attrib][0]\n",
        "    total_neg_prob*=prob_dict[each_attrib][1]\n",
        "\n",
        "  if(total_pos_prob>total_neg_prob):\n",
        "    pred='yes'\n",
        "  else:\n",
        "    pred='no'\n",
        "  pred_list.append(pred)\n",
        "print('Actual values:\\n',test_target)\n",
        "print('Predicted values:\\n',pred_list)\n",
        "acc=0\n",
        "for i,j in zip(test_target,pred_list):\n",
        "  if(i==j):\n",
        "    acc+=1\n",
        "accuracy=acc*100/np.shape(test_target)[0]\n",
        "print('Accuracy={0} %'.format(accuracy))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual values:\n",
            " ['no' 'yes' 'no' 'yes' 'no']\n",
            "Predicted values:\n",
            " ['no', 'yes', 'yes', 'yes', 'yes']\n",
            "Accuracy=60.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}